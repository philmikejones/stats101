{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.stats\n",
    "\n",
    "food = pd.read_pickle(\"../data/processed/food\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pearson's correlation coefficient, $r$\n",
    "\n",
    "$r$ is standardised, which is useful because:\n",
    "\n",
    "- tests of all sorts of units can be compared which each other,\n",
    "- the result is between -1 (perfect negative association), through 0 (no association), and 1 (perfect positive association)\n",
    "\n",
    "$r$ is a measure of effect size (or correlation) between two numerical variables.\n",
    "It works on the principle that as the difference from the mean for one variable increases we expect the difference from the mean for the related variable to increase (positive correlation) or decrease (negative correlation).\n",
    "\n",
    "For example the mean income is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food.P344pr.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we hypothesise that people with higher incomes spend more money on food (they have more money to shop at Waitrose).\n",
    "Expenditure is top--coded, so let's trim the data like we did for income and take a look at the resulting distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food = food[food.P550tpr < food.P550tpr.max()]\n",
    "food.hist(column = \"P550tpr\", bins = 100)\n",
    "plt.xlabel(\"Food expenditure (Â£)\")\n",
    "plt.ylabel(\"Frequency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean expenditure is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food.P550tpr.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we take an individual with a high income (their income deviates from the mean) we would expect their expenditure to also deviate from the expenditure mean.\n",
    "These deviations from the mean are their variances, so we are stating that we expect income and expenditure on food to **covary**.\n",
    "This principle is used to calculate the **Pearson correlation coefficient** (usually just called the correlation), which is a standardised measure of how much the two variables vary together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.pearsonr(\n",
    "    food[\"P344pr\"], food[\"P550tpr\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example the first number is the correlation coefficient and the second number is its associated $p$ value.\n",
    "\n",
    "The correlation is positive so as income goes up, expenditure on food goes up (if it were negative it would be a negative correlation, which would state that as income went up expenditure on food went down for some reason).\n",
    "The value of 0.63 suggests quite a lot of the variance in expenditure is accounted for by income (so the correlation is strong).\n",
    "\n",
    "The $p$ value is $<< 0.01$ ($<<$ means 'much less than') so it is highly improbable we would see a correlation this large by chance alone, so we have strong evidence to reject the null hypothesis and conclude that there is an association between income and expenditure on food.\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "Pearson's correlation coefficient assumes that both variables are numeric and normally distributed for the $p$ value to be accurate.\n",
    "In this case our variables are numeric (income and expenditure) so this assumption is met.\n",
    "\n",
    "Neither variable should have any outliers (defined as any value greater than the mean + 3.29 standard deviations).\n",
    "For income this is ok:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(\n",
    "    food[food.P344pr > \n",
    "                 food.P344pr.mean() + (3.29 * food.P344pr.std())]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But there are a few outliers for the expenditure variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(\n",
    "    food[food.P550tpr > \n",
    "                 food.P550tpr.mean() + (3.29 * food.P550tpr.std())]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be safe, let's remove these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food = food[food.P550tpr < food.P550tpr.mean() + (3.29 * food.P550tpr.std())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A scatterplot of these two variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food.plot.scatter(\"P344pr\", \"P550tpr\")\n",
    "plt.xlabel(\"Income\")\n",
    "plt.ylabel(\"Expenditure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The points should be linear (i.e. a straight line) and roughly cylindrical to meet the assumptions.\n",
    "If it's too conincal it means the deviances aren't consistent (heteroskedasticity).\n",
    "\n",
    "If these assumptions aren't true of our data we can use **Spearman's $\\rho$** (pronounced 'row').\n",
    "Spearman's $\\rho$ is also useful when we have a numeric variable and an ordinal variable (something we couldn't test with Pearson's $r$).\n",
    "\n",
    "This is a **non--parametric** test.\n",
    "Non--parametric tests tend to be more robust (which is why we can use them when we violate some of the assumptions of the parametric equivalents, in this case Pearon's $r$) but sometimes have lower statistical power.\n",
    "Therefore, try to use the parametric version by default and switch to the non--parametric version when necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.spearmanr(\n",
    "    food[\"P344pr\"], food[\"P550tpr\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in this example the correlation statistic is very similar and the $p$ value is still significant ($<< 0.01$)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
