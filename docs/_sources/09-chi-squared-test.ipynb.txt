{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chi--squared test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import scipy.stats\n",
    "\n",
    "food = pd.read_pickle(\"../data/processed/food\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To carry out the $\\chi ^ 2$ test, the [`scipy.stats.chi2_contingency()`](https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.stats.chi2_contingency.html) function returns the following pieces of information:\n",
    "\n",
    "- The test statistic\n",
    "- The $p$ value\n",
    "- The number of [degrees of freedom](https://en.wikipedia.org/wiki/Degrees_of_freedom_(statistics))\n",
    "- The expected counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.stats.chi2_contingency(\n",
    "    pd.crosstab(index = food.A094r, columns = food.A121r, margins = False)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test statistic is, roughly, the amount of variance explained by our test compared to the amount of variance not explained.\n",
    "In all my years of statistics I have never worked one of these out by hand, so don't worry too much about this.\n",
    "\n",
    "The degrees of freedom are the the number of independent pieces of information to perform the test on (a bit like we saw earlier with the standard deviation, the DOF used is $n - 1$ because we set the population mean to be the sample mean).\n",
    "In a cross tab this is the number of rows minus 1, multiplied by the number of columns minus 1, in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(5 - 1) * (3 - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is because, in this example, once we know rows 1--4 we can calculate row 5 because we know the total.\n",
    "Similarly once we know columns 1--2 we can calculate column 3 because we know the total.\n",
    "\n",
    "We're not interested in the test statistic or degrees of freedom directly, but these are used to calculate the $p$ value.\n",
    "We want the $p$ value to be low, by convention at least below 0.05.\n",
    "\n",
    "In this case the $p$ value is so low it is returned in scientific notation.\n",
    "The `3.2e-144` means the decimal place is moved 144 places to the left, i.e.:\n",
    "\n",
    "`0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000003`\n",
    "\n",
    "So, essentially, zero (in fact it's *highly* dubious that the p value is known to this level of accuracy, so we treat it as essentially zero).\n",
    "A $p$ value this small means it is very, very unlikely that we would have observed the relationship we did just by chance, so we can say with some confidence that there is an association or link between NS-SEC and housing tenure.\n",
    "\n",
    "There are a few important assumptions we must satisfy to use a chi--squared test.\n",
    "One of these is to do with *expected frequencies*, which are used in calculating the actual chi--squared statistic.\n",
    "In calculating the chi--squared statistic we calculate the expected frequency for each cell.\n",
    "In our example we have 15 cells in our crosstab, so we calculate 15 expected frequencies.\n",
    "\n",
    "Specifically we should not have any expected frequencies of 0 (should be at least 1), and no more than 20% of expected frequencies should be less than 5.\n",
    "To calculate the expected frequency for each cell we use the formula:\n",
    "\n",
    "$$\n",
    "E_{ij} = \\frac{T_{i} x T_{j}}{N}\n",
    "$$\n",
    "\n",
    "where $E_{ij}$ is the expected frequency of cell in row $_i$ and column $_j$; $T_i$ is the total of row $_i$; $T_j$ is the total of column $_j$; and $N$ is the table grand total.\n",
    "So the expected frequency for row 1, column 1 is:\n",
    "\n",
    "$$\n",
    "E_{1, 1} = \\frac{1589 x 880}{5144}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1589 * 880) / 5144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is what is returned by the `scipy.stats.chi_contingency()` function.\n",
    "\n",
    "When running a chi--square test on a 2x2 contingency table it is likely to produce p values that are too small (i.e. it's more likely to make a false positive or a [type I error](#interpreting-the-results).\n",
    "To correct this `scipy.stats.chi_contingency()` automatically applies the [**Yates's continuity correction**](https://en.wikipedia.org/wiki/Yates%27s_correction_for_continuity) if you're performing a test on a 2x2 table.\n",
    "I've never worried about what this is or how it works (although Andy Field's textbook, as usual, covers it in an accessible way); just know that it has been applied when reporting on a 2x2 table."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
