[
["index.html", "STATS101 1 Introduction 1.1 Why use statistics?", " STATS101 Phil Mike Jones 2018-09-28 1 Introduction 1.1 Why use statistics? As social scientists and researchers we want to answer questions about the social world. At its most simplistic (and I completely acknowledge that I’m massively generalising here), we usually seek to describe the world or quantify the world. For these tasks we use qualitative methods and quantitative methods respectively. To quantify the world we might want to know things like, “how many people have been a victim of crime?”, “how many people have mental health problems?”, or “how many people have social science degrees?”. Sometimes we have complete (or near–complete) data about everybody in a population. For example, in the UK the decennial (i.e. every ten years) census is a count of everybody, including certain characteristics such as health, education, and employment. In this case the population is everybody in the UK. More often than not it is impractical to ask everybody our questions. Usually the cost and time required to carry out such a survey prohibit asking every single person what we want to know, but also very few people would answer everything that they were asked (the only reason everybody responds to the census is because it’s a crime not to complete the census and people have been prosecuted for not completing it). Instead we take a sample of the population, and infer, from our sample, what the population is like. For example, we might ask a random sample of 1,000 people what their favourite hot drink is. It’s not that we want to know what this 1,000 people think more than any other 1,000 people. Instead, they are our sample and, based on their responses, we can infer what the most popular hot drink is for the population. In the UK, the most popular hot drink is tea, but everybody knows it should be coffee. Figure 1.1: Coffee is clearly better than tea Obtaining knowledge about a population by inferring from a sample is the cornerstone of quantitative social science research, and uses many statistical techniques to be able to do this. The good news is the most difficult challenge is often deciding which technique to use; using the technique is often like following a recipe. "],
["levels-of-measurement.html", "2 Levels of measurement 2.1 Nominal 2.2 Ordinal 2.3 Interval 2.4 Ratio", " 2 Levels of measurement Levels of measurement describe the nature of your data point. They are important because they determine what statistical tests you can perform on them. The four levels of measurement are: 2.1 Nominal Also known as categorical. These are labels such as male/female; no religion/religion. They have no inherent order; one response is not ‘better’ or ‘higher’ than another. As social scientists you’ll find these are pretty common. In R these are stored as character or factor. Factors were historically more common, but the character class is more flexible and more compatible with other formats. A common practice is to set up variables as character and convert to factor if and when needed. 2.2 Ordinal Similar to nominal in that they are labels (rather than numbers), but the labels have a rank or order. For example, a ‘strongly disagree’ to ‘strongly agree’ scale is ordinal. Another example would be ‘guilty’ and ‘not guilty’. In R these are stored as character or factor (with ordered = TRUE). 2.3 Interval Interval data is numerical but does not have a meaningful zero value. The most common example often given is temperature expressed in degrees celcius. A temperature of 20°C is not twice as hot as 10°C, because 0°C is arbitrary rather than based on the absence of heat. A more common example in the social sciences is date. Years are based on an arbitrary zero (0AD); months are based on twelve months that do not have a ‘zero’; days do not have a zero and reset each month. In R these are stored as numerical, of which there are integer and double classes. 2.4 Ratio Ratio data is again numerical, but differs from interval because it has a meaningful, non–arbitrary, zero. As we saw above dates are interval, but age in years is ratio because zero years old is the lowest age you can be. It is more common for numerical data to be ratio than interval. Other examples include income and number of events (e.g. number of crimes in an area). In R these are stored as numerical, of which there are integer and double classes. double is more usualy but integer is useful sometimes, for example for ages. "],
["central-tendency.html", "3 Central tendency 3.1 Mode 3.2 Median 3.3 Mean", " 3 Central tendency Measures of central tendency is a fancy phrase for ‘average’. They are a single data point used to represent a ‘typical’ value from your data. Depending on your level of measurement you can use one or more measures of central tendency. 3.1 Mode The most common unique value. For example, 10 people are asked their favourite drink and you have the following results: ## [1] &quot;espresso&quot; &quot;latte&quot; &quot;tea&quot; &quot;tea&quot; ## [5] &quot;earl gray&quot; &quot;americano&quot; &quot;hot chocolate&quot; &quot;tea&quot; ## [9] &quot;hot chocolate&quot; &quot;tea&quot; The most common result (mode) is tea, which we can confirm with a quick frequency table: table(drink) ## drink ## americano earl gray espresso hot chocolate latte ## 1 1 1 2 1 ## tea ## 4 Mode is the only measure of central tendency you can provide for nominal data. 3.2 Median The median is the ‘middle’ point. It’s only appropriate for ordered data and is calculated by arranging your data in order and selecting the mid–point. Consider the following incomes: ## [1] 27300 Which looks like this when we plot it as a distribution: ggplot(dat, aes(income)) + geom_histogram(bins = 10) Figure 3.1: Distribution of simulated income data If we arrange these in order and take the middle point we obtain the median income: ## [1] 27300 If your data have an even number of items, the median is the mean (average) of the two points. The median is often considered more robust than the mean, which means it is less susceptible to outliers, for reasons we’ll get to in a moment. 3.3 Mean The mean is what most people think of when they think of an average. You simply “add them all up and divide by how many you have”. For example, the mean of the incomes we simulated above is: mean(dat$income) ## [1] 27300 In this case the mean and the median of this variable are the same: all.equal( mean(dat$income), median(dat$income) ) ## [1] TRUE But this is because this variable is set up to be a normal distribution (more on that later, but for now just think of it as a perfect distribution with perfect properties from a modelling perspective). In the wild, most distributions are not exactly normal (or ideal) so the mean and the median differ. For example with income there are a relatively small number of individuals with an income substantially higher than is typical. This leads to a skew in the income distribution, and this makes out mean higher. Let’s add a couple of very wealthy individuals to our data set: dat$income_skewed = dat$income # first copy the income data dat$income_skewed[49] = 1200000 dat$income_skewed[48] = 1100000 These individuals have an income of £1.2 and £1.1 million. Compare this distribution to our earlier income distribution using the same settings: ggplot(dat) + geom_histogram(aes(income_skewed), bins = 100) We can see effectively our original plot on the left, but now there are two individuals out on their own earning substantially more than anyone else. These individuals don’t affect the median: median(dat$income_skewed) ## [1] 27300 But the mean is now: mean(dat$income_skewed) ## [1] 72348.07 This is now no longer representative of any individual in the data set; it’s floating out in the gap between observed incomes. For this reason we often consider the median a more robust measure of central tendency than the mean, and why you should be careful when someone presents a mean value without any additional information "],
["measures-of-spread.html", "4 Measures of spread 4.1 Variance 4.2 Standard deviation", " 4 Measures of spread We saw in the measures of central tendency chapter that the mean can be a poor representation of data if the data is skewed, and that we should therefore be careful when someone presents us with a mean (or average) without any further information. One of the types of ‘further information’ that can help us is a measure of spread of the data around the mean value. We usually use the variance and the standard deviation to quantify measure of spread. Both are easy to calculate, and even easier to convert between each other. 4.1 Variance Lets recap: this is what the income data looks like: dat %&gt;% unlist() %&gt;% as.vector() ## [1] 6762.511 9793.139 11752.264 13249.284 14484.484 ## [6] 15550.132 16496.807 17355.421 18146.349 18883.788 ## [11] 19578.068 20236.974 20866.546 21471.585 22055.995 ## [16] 22623.012 23175.369 23715.412 24245.192 24766.529 ## [21] 25281.065 25790.308 26295.663 26798.464 27300.000 ## [26] 27801.536 28304.337 28809.692 29318.935 29833.471 ## [31] 30354.808 30884.588 31424.631 31976.988 32544.005 ## [36] 33128.415 33733.454 34363.026 35021.932 35716.212 ## [41] 36453.651 37244.579 38103.193 39049.868 40115.516 ## [46] 41350.716 42847.736 44806.861 47837.489 6762.511 ## [51] 9793.139 11752.264 13249.284 14484.484 15550.132 ## [56] 16496.807 17355.421 18146.349 18883.788 19578.068 ## [61] 20236.974 20866.546 21471.585 22055.995 22623.012 ## [66] 23175.369 23715.412 24245.192 24766.529 25281.065 ## [71] 25790.308 26295.663 26798.464 27300.000 27801.536 ## [76] 28304.337 28809.692 29318.935 29833.471 30354.808 ## [81] 30884.588 31424.631 31976.988 32544.005 33128.415 ## [86] 33733.454 34363.026 35021.932 35716.212 36453.651 ## [91] 37244.579 38103.193 39049.868 40115.516 41350.716 ## [96] 42847.736 1100000.000 1200000.000 To calculate the variance: subtract the mean from each score square the result sum the results to produce one value divide by \\(n - 1\\) (number of observations minus one) \\[ \\tag{4.1} \\frac{\\Sigma (x - \\bar{x}) ^ 2}{N-1} \\] Using \\(n - 1\\) rather than simply the number of observations is known as Bessel’s correction. To calculate the variance of the population we must assume that the population mean is the same as the sample mean that we have observed. In fixing the population mean we reduce the degrees of freedom of our observations, because if we change these the final observation is determined in order for the mean to remain constant. For example if our sample mean is 100 we assume our population mean is 100. If we have two observations these might be 110 and 90 (mean 100). If we change the 110 value to 120, the 90 value must change to 80 to ensure the sample mean (and therefore the population mean) remains 100, so there is only one degree of freedom. We would therefore use \\(2 - 1\\) as the denominator in our variance calculation. var(dat$income) ## [1] 88642982 4.2 Standard deviation As you’ve probably noticed the variance is not in the units of the original data (otherwise the variance would be £88642981.9934468). This is where the standard deviation comes in. In fact the unit of the variance is the square of the unit of the original data. The standard deviation is therefore a measure of spread in the unit of the original data, and is calculated simply by square rooting the variance. \\[ \\tag{4.2} \\sqrt{\\frac{\\Sigma (x - \\bar{x}) ^ 2}{N-1}} \\] The standard deviation of the income is therefore: sd(dat$income) ## [1] 9415.04 The standard deviation is a measure of how far the data points are on average from the mean. A small standard deviation means the mean fairly accurately represents the data; a large standard deviation means the mean does not represent the data well. "]
]
