{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "These are my notes on statistics and quantitative methods for analysis in the social sciences.\n",
    "\n",
    "## Why use statistics?\n",
    "\n",
    "As social scientists and researchers we want to answer questions about the social world.\n",
    "At its most simplistic (and I completely acknowledge that I'm massively generalising here), we usually seek to describe the world or quantify the world.\n",
    "For these tasks we use qualitative methods and quantitative methods respectively.\n",
    "\n",
    "To quantify the world we might want to know things like, \"how many people have been a victim of crime?\", \"how many people have mental health problems?\", or \"how many people have social science degrees?\".\n",
    "\n",
    "Sometimes we have complete (or near--complete) data about everybody in a population.\n",
    "For example, in the UK the decennial (i.e. every ten years) census is a count of everybody, including certain characteristics such as health, education, and employment.\n",
    "In this case the population is everybody in the UK.\n",
    "\n",
    "More often than not it is impractical to ask everybody our questions.\n",
    "Usually the cost and time required to carry out such a survey prohibit asking every single person what we want to know, but also very few people would answer everything that they were asked (the only reason everybody responds to the census is because [it's a crime not to complete the census](https://en.wikipedia.org/wiki/Census_in_the_United_Kingdom#Criminal_law) and [people have been prosecuted for not completing it](https://www.theguardian.com/uk/2012/jan/27/120-convicted-census-forms-2011)).\n",
    "Instead we take a *sample* of the population, and *infer*, from our sample, what the population is like.\n",
    "\n",
    "For example, we might ask a random sample of 1,000 people what their favourite hot drink is.\n",
    "It's not that we want to know what this 1,000 people think more than any other 1,000 people.\n",
    "Instead, they are our *sample* and, based on their responses, we can *infer* what the most popular hot drink is for the *population*.\n",
    "In the UK, the [most popular hot drink is tea](https://www.statista.com/statistics/697383/favorite-hot-drinks-united-kingdom-uk/), but everybody knows it should be coffee.\n",
    "\n",
    "![Coffee is clearly superior to tea](\"images/coffee.jpg\")\n",
    "\n",
    "Obtaining knowledge about a *population* by *inferring* from a *sample* is the cornerstone of quantitative social science research, and uses many statistical techniques to be able to do this.\n",
    "The good news is the most difficult challenge is often deciding which technique to use; using the technique is often like following a recipe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages\n",
    "\n",
    "I use `python3` to process and analyse the data, and a number of packages install through anaconda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import shutil\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sources\n",
    "\n",
    "These tutorials use a number of teaching data sets available from the [UK Data Service](https://www.ukdataservice.ac.uk/) under terms of the [Open Government License](http://www.nationalarchives.gov.uk/doc/open-government-licence/version/3/):\n",
    "\n",
    "> Office for National Statistics, University of Manchester, Cathie Marsh Institute for Social Research (CMIST), UK Data Service, 2016, Living Costs and Food Survey, 2013: Unrestricted Access Teaching Dataset, [data collection], Office for National Statistics, 2nd Edition, Office for National Statistics, [original data producer(s)]. Accessed 1 October 2018. SN: 7932, http://doi.org/10.5255/UKDA-SN-7932-2. Contains public sector information licensed under the Open Government Licence v2.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "food = \"https://beta.ukdataservice.ac.uk/Umbraco/Surface/Discover/GetDownload?studyNumber=7932&fileName=7932tab_818dcb297393b2557b07f05acaae70b9.zip\"\n",
    "food = requests.get(food)\n",
    "food = food.content\n",
    "outfile = open(\"../data/external/food.zip\", \"wb\")\n",
    "outfile.write(food)\n",
    "\n",
    "shutil.unpack_archive(\"../data/external/food.zip\", extract_dir = \"../data/external/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "food = pd.read_csv(\n",
    "    \"../data/external/UKDA-7932-tab/tab/lcfs_2013_teaching.tab\",\n",
    "    sep = \"\\t\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Levels of measurement\n",
    "\n",
    "Levels of measurement describe the nature of your data point.\n",
    "They are important because they determine what statistical tests you can perform on them.\n",
    "The four levels of measurement are:\n",
    "\n",
    "\n",
    "## Nominal\n",
    "\n",
    "Also known as **categorical**.\n",
    "These are labels such as male/female; no religion/religion.\n",
    "They have no inherent order; one response is not 'better' or 'higher' than another.\n",
    "As social scientists you'll find these are pretty common.\n",
    "\n",
    "\n",
    "## Ordinal\n",
    "\n",
    "Similar to nominal in that they are labels (rather than numbers), but the labels have a rank or order.\n",
    "For example, a 'strongly disagree' to 'strongly agree' scale is ordinal.\n",
    "Another example would be 'guilty' and 'not guilty'.\n",
    "\n",
    "\n",
    "## Interval\n",
    "\n",
    "Interval data is numerical but does not have a meaningful zero value.\n",
    "The most common example often given is temperature expressed in degrees celcius.\n",
    "A temperature of 20&deg;C is not twice as hot as 10&deg;C, because 0&deg;C is arbitrary rather than based on the absence of heat.\n",
    "\n",
    "A more common example in the social sciences is date.\n",
    "Years are based on an arbitrary zero (0AD); months are based on twelve months that do not have a 'zero'; days do not have a zero and reset each month.\n",
    "\n",
    "\n",
    "## Ratio\n",
    "\n",
    "Ratio data is again numerical, but differs from interval because it has a meaningful, non--arbitrary, zero.\n",
    "As we saw above dates are interval, but age in years is ratio because zero years old is the lowest age you can be.\n",
    "\n",
    "It is more common for numerical data to be ratio than interval.\n",
    "Other examples include income and number of events (e.g. number of crimes in an area).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Central tendency\n",
    "\n",
    "Measures of central tendency is a fancy phrase for 'average'.\n",
    "They are a single data point used to represent a 'typical' value from your data.\n",
    "Depending on your level of measurement you can use one or more measures of central tendency.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mode\n",
    "\n",
    "The most common value.\n",
    "Mode is the only measure of central tendency you can provide for [nominal data](../levels-of-measurement#nominal).\n",
    "\n",
    "For example, the variable `A121r` in our food data set is of household tenure type.\n",
    "The available options are:\n",
    "\n",
    "1. public rented (i.e. rented from a council)\n",
    "2. private rented (i.e. rented from a landlord)\n",
    "3. owned\n",
    "\n",
    "A frequency (count) table of this variable shows that `owned` is the most common type of tenure:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "owned             3466\n",
       "public rented      880\n",
       "private rented     798\n",
       "Name: A121r, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food[\"A121r\"] = food[\"A121r\"].astype(\"category\")\n",
    "food[\"A121r\"].cat.categories = [\"public rented\", \"private rented\", \"owned\"]\n",
    "food[\"A121r\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Median\n",
    "\n",
    "The median is the 'middle' point.\n",
    "It's only appropriate for ordered data (i.e. ordinal or numeric) and is calculated by arranging your data in order and selecting the mid--point.\n",
    "`P344pr` is the gross normal weekly household income for each respondent (note that these have been [top--coded](https://en.wikipedia.org/wiki/Top-coded), but we can ignore this for our example).\n",
    "The following are incomes for the first five respondents as an example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    465.36\n",
       "1    855.26\n",
       "2    160.96\n",
       "3    656.22\n",
       "4    398.80\n",
       "Name: P344pr, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "food[\"P344pr\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which looks like this when we plot it as a distribution:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert plot here"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If we arrange these in order and take the middle point we obtain the median income:\n",
    "\n",
    "```{r median-result, include=TRUE, echo=FALSE, eval=FALSE}\n",
    "median(dat$income)\n",
    "```\n",
    "\n",
    "If your data have an even number of items, the median is the mean (average) of the two points.\n",
    "The median is often considered more *robust* than the mean, which means it is less susceptible to outliers, for reasons we'll get to in a moment.\n",
    "\n",
    "\n",
    "## Mean\n",
    "\n",
    "The mean is what most people think of when they think of an average.\n",
    "You simply \"add them all up and divide by how many you have\".\n",
    "For example, the mean of the incomes we simulated above is:\n",
    "\n",
    "```{r mean, eval=FALSE}\n",
    "mean(dat$income)\n",
    "```\n",
    "\n",
    "In this case the mean and the median of this variable are the same:\n",
    "\n",
    "```{r mean-median-equal, eval=FALSE}\n",
    "all.equal(\n",
    "  mean(dat$income),\n",
    "  median(dat$income)\n",
    ")\n",
    "```\n",
    "\n",
    "But this is because this variable is set up to be a normal distribution (more on that later, but for now just think of it as a perfect distribution with perfect properties from a modelling perspective).\n",
    "In the wild, most distributions are not exactly normal (or ideal) so the mean and the median differ.\n",
    "For example with income there are a relatively small number of individuals with an income substantially higher than is typical.\n",
    "This leads to a skew in the income distribution, and this makes out mean higher.\n",
    "\n",
    "Let's add a couple of very wealthy individuals to our data set:\n",
    "\n",
    "```{r add-millionnaires, eval=FALSE}\n",
    "dat$income_skewed = dat$income  # first copy the income data\n",
    "dat$income_skewed[49] = 1200000\n",
    "dat$income_skewed[48] = 1100000\n",
    "```\n",
    "\n",
    "These individuals have an income of £1.2 and £1.1 million.\n",
    "Compare this distribution to our earlier income distribution using the same settings:\n",
    "\n",
    "```{r distribution-skewed, cache=TRUE, eval=FALSE}\n",
    "ggplot(dat) + geom_histogram(aes(income_skewed), bins = 100)\n",
    "```\n",
    "\n",
    "We can see effectively our original plot on the left, but now there are two individuals out on their own earning substantially more than anyone else.\n",
    "These individuals don't affect the median:\n",
    "\n",
    "```{r median-skewed, eval=FALSE}\n",
    "median(dat$income_skewed)\n",
    "```\n",
    "\n",
    "But the mean is now:\n",
    "\n",
    "```{r mean-skewed, eval=FALSE}\n",
    "mean(dat$income_skewed)\n",
    "```\n",
    "\n",
    "This is now no longer representative of any individual in the data set; it's floating out in the gap between observed incomes.\n",
    "For this reason we often consider the median a more *robust* measure of central tendency than the mean, and why you should be careful when someone presents a mean value without any additional information\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Measures of spread\n",
    "\n",
    "We saw in the measures of central tendency chapter that the mean can be a poor representation of data if the data is skewed, and that we should therefore be careful when someone presents us with a mean (or average) without any further information.\n",
    "\n",
    "One of the types of 'further information' that can help us is a measure of spread of the data around the mean value.\n",
    "We usually use the *variance* and the *standard deviation* to quantify measure of spread.\n",
    "Both are easy to calculate, and even easier to convert between each other.\n",
    "\n",
    "\n",
    "## Variance\n",
    "\n",
    "Lets recap: this is what the income data looks like:\n",
    "\n",
    "```{r income, eval=FALSE}\n",
    "dat %>% \n",
    "  unlist() %>% \n",
    "  as.vector()\n",
    "```\n",
    "\n",
    "To calculate the variance:\n",
    "\n",
    "1. subtract the mean from each score\n",
    "1. square the result\n",
    "1. sum the results to produce one value\n",
    "1. divide by $n - 1$ (number of observations minus one)\n",
    "\n",
    "$$\n",
    "(\\#eq:variance)\n",
    "\\frac{\\Sigma (x - \\bar{x}) ^ 2}{N-1}\n",
    "$$\n",
    "\n",
    "Using $n - 1$ rather than simply the number of observations is known as [Bessel's correction](https://en.wikipedia.org/wiki/Bessel%27s_correction).\n",
    "To calculate the variance of the population we must assume that the population mean is the same as the sample mean that we have observed.\n",
    "In fixing the population mean we reduce the degrees of freedom of our observations, because if we change these the final observation is determined in order for the mean to remain constant.\n",
    "\n",
    "For example if our sample mean is 100 we assume our population mean is 100.\n",
    "If we have two observations these might be 110 and 90 (mean 100).\n",
    "If we change the 110 value to 120, the 90 value *must* change to 80 to ensure the sample mean (and therefore the population mean) remains 100, so there is only one degree of freedom.\n",
    "We would therefore use $2 - 1$ as the denominator in our variance calculation.\n",
    "\n",
    "```{r income-variance, eval=FALSE}\n",
    "var(dat$income)\n",
    "```\n",
    "\n",
    "\n",
    "## Standard deviation\n",
    "\n",
    "As you've probably noticed the variance is not in the units of the original data (otherwise the variance would be £` var(dat$income)`).\n",
    "This is where the standard deviation comes in.\n",
    "In fact the unit of the variance is the *square* of the unit of the original data.\n",
    "The standard deviation is therefore a measure of spread in the unit of the original data, and is calculated simply by square rooting the variance.\n",
    "\n",
    "$$\n",
    "(\\#eq:standard-deviation)\n",
    "\\sqrt{\\frac{\\Sigma (x - \\bar{x}) ^ 2}{N-1}}\n",
    "$$\n",
    "\n",
    "The standard deviation of the income is therefore:\n",
    "\n",
    "```{r income-sd, eval=FALSE}\n",
    "sd(dat$income)\n",
    "```\n",
    "\n",
    "The standard deviation is a measure of how far the data points are on average from the mean.\n",
    "A small standard deviation means the mean fairly accurately represents the data; a large standard deviation means the mean does not represent the data well.\n",
    "\n",
    "\n",
    "## Standard error and confidence intervals\n",
    "\n",
    "Standard error is effectively the standard deviation of the population mean.\n",
    "The standard deviation quantifies how well the sample mean fits the observed (i.e. sample) data, not the population, but we're really interested in how well our sample mean represents the population.\n",
    "\n",
    "Because any sample we take from the population is going to be slightly different from all other samples (because everything varies) each sample mean is going to be slightly different from every other.\n",
    "The standard error of the mean is a measure of how confident our sample mean matches the population mean.\n",
    "\n",
    "One approach to calculate the standard error of the mean would be to take multiple samples.\n",
    "The mean of each of these samples would form a sampling distribution due to variation: some sample means would be lower than the population mean; some sample means would be higher than the population mean; and many would be the same.\n",
    "These sample mean values would form a normal distribution around the population mean.\n",
    "\n",
    "The standard deviation of these sample means would tell us how well our sample means fit the population mean.\n",
    "This is known as the standard error of the mean ($SE_{\\bar{x}}$).\n",
    "\n",
    "In practice we can usually only take one sample so we can estimate it with:\n",
    "\n",
    "$$\n",
    "(\\#eq:standard-error)\n",
    "\\sigma_{\\bar{x}} = \\frac{s}{\\sqrt{n}}\n",
    "$$\n",
    "\n",
    "where $\\sigma_{\\bar{x}}$ is the standard error of the population mean, $s$ is the sample standard deviation, and $n$ is the number of observations in the sample.\n",
    "\n",
    "We can demonstrate this with the census (in fact, we could demonstrate this with any data set and pretend it's the population and take multiple samples from it, but why not just use an actual population?).\n",
    "I'm using ages of all people in Sheffield in 2011 to illustrate this, which I download from Nomisweb:\n",
    "\n",
    "```{r download-sheffield-age, cache=TRUE, message=FALSE, eval=FALSE}\n",
    "tempdir = tempdir()\n",
    "download.file(\n",
    "  \"https://www.nomisweb.co.uk/api/v01/dataset/NM_503_1.data.csv?date=latest&geography=1946157123&rural_urban=0&c_age=1...101&measures=20100&signature=NPK-0c73734c0f725c979cee3a:0xa9b892a105be9e9449cdb6c88bdac678e12b229e\",\n",
    "  destfile = paste0(tempdir, \"census.csv\")\n",
    ")\n",
    "\n",
    "age = readr::read_csv(paste0(tempdir, \"census.csv\"))\n",
    "\n",
    "age =\n",
    "  age %>% \n",
    "  select(C_AGE_NAME, OBS_VALUE) %>% \n",
    "  filter(C_AGE_NAME != \"Age 100 and over\") %>% \n",
    "  mutate(\n",
    "    C_AGE_NAME = if_else(C_AGE_NAME == \"Age under 1\", \"0\", C_AGE_NAME)\n",
    "  ) %>% \n",
    "  mutate(C_AGE_NAME = str_replace(C_AGE_NAME, \"Age \", \"\")) %>% \n",
    "  mutate(C_AGE_NAME = as.integer(C_AGE_NAME)) %>% \n",
    "  uncount(OBS_VALUE)\n",
    "```\n",
    "\n",
    "Figure \\@ref(fig:age-hist) is a histogram of ages in people in Sheffield from the 2011 Census.\n",
    "\n",
    "```{r age-hist, fig.height=3.5, fig.cap=\"Histogram of ages in Sheffield\", cache=TRUE, eval=FALSE}\n",
    "ggplot(age) + geom_histogram(aes(C_AGE_NAME), binwidth = 1) +\n",
    "  xlab(\"Age\") + ylab(\"Frequency\")\n",
    "```\n",
    "\n",
    "```{r mode-age, eval=FALSE}\n",
    "mode_age =\n",
    "  age %>% \n",
    "  count(C_AGE_NAME) %>% \n",
    "  arrange(desc(n)) %>% \n",
    "  filter(row_number() == 1) %>% \n",
    "  select(C_AGE_NAME) %>% \n",
    "  unlist()\n",
    "```\n",
    "\n",
    "The modal age is ` mode_age`; the median age is ` median(age$C_AGE_NAME)`; and crucially the mean age is ` mean(age$C_AGE_NAME)`.\n",
    "\n",
    "Let's take 1,000 samples from the population, and make a sampling distribution of these means:\n",
    "\n",
    "```{r sample-age-1000, eval=FALSE}\n",
    "set.seed(42)\n",
    "samples = replicate(1000, sample_n(age, 1000))\n",
    "samples = map(samples, mean)\n",
    "samples = do.call(rbind, samples)\n",
    "colnames(samples) = \"mean_age\"\n",
    "samples = as.data.frame(samples)\n",
    "```\n",
    "\n",
    "```{r samples-age-hist, cache=TRUE, fig.cap=\"Histogram of samples from age data set\", fig.height=3.5, eval=FALSE}\n",
    "ggplot(samples) + geom_histogram(aes(mean_age), bins = 50) +\n",
    "  xlab(\"Sample mean age\") + ylab(\"Frequency\")\n",
    "```\n",
    "\n",
    "From Figure \\@ref(fig:samples-age-hist) most sample means are around 38, although a few are as low as 36 and as high as 40.\n",
    "Remember we know are population mean is ` mean(age$C_AGE_NAME)` but we wouldn't normally know this.\n",
    "If we just had access to one sample, how would we know if the resultant sample mean was close to the population mean?\n",
    "From the histogram of sample means we can see that it's more likely to end up with a sample mean that's close to the population mean than one that's incorrect, and we can quantify this with a confidence interval.\n",
    "\n",
    "Let's take a sample of 1000 random cases from this data set and pretend it's all we have access to:\n",
    "\n",
    "```{r age-sample, eval=FALSE}\n",
    "age_sample =\n",
    "  age %>% \n",
    "  sample_n(1000)\n",
    "```\n",
    "\n",
    "The mean of this sample is ` mean(age_sample$C_AGE_NAME)`, very close to the population mean but not quite the same.\n",
    "The standard error of this sample is:\n",
    "\n",
    "```{r standard-error-sample-age, eval=FALSE}\n",
    "se_age = sd(age_sample$C_AGE_NAME) / sqrt(nrow(age_sample))\n",
    "se_age\n",
    "```\n",
    "\n",
    "We know that an ideal normal distribution will have [95\\% of cases within 1.96 standard deviations of the mean](https://en.wikipedia.org/wiki/Normal_distribution#Standard_deviation_and_coverage).\n",
    "If we multiply our standard error by $\\pm$ 1.96 that therefore defines a 95\\% confidence interval.\n",
    "In this case ` mean(age_sample$C_AGE_NAME) - (1.96 * se_age)` to ` mean(age_sample$C_AGE_NAME) + (1.96 * se_age)`.\n",
    "This effectively estimates that if we were to take 100 samples the population mean would fall within these bounds 95 times.\n",
    "In our example the population mean is indeed within the 95\\% confidence interval of the sample mean.\n",
    "\n",
    "To calculate 99\\% confidence intervals use 2.58 standard deviations rather than 1.96, in this example resulting in a confidence interval between ` mean(age_sample$C_AGE_NAME) - (2.58 * se_age)` and ` mean(age_sample$C_AGE_NAME) + (2.58 * se_age)`\n",
    "Perhaps counterintuitively this results in a wider interval (because the interval ensures the population mean falls within these bounds 99 times instead of 95); it is not more precise.\n",
    "\n",
    "From the standard error of the mean and confidence interval we can therefore quantify how confident we are that the sample mean is close to the true population mean.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
